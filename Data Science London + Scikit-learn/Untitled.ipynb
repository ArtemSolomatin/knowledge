{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "\n",
    "#splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#regression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv', header=None)\n",
    "train_labels = pd.read_csv('input/train_labels.csv', header=None)\n",
    "test = pd.read_csv('input/test.csv', header=None)\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9     ...           30        31        32  \\\n",
       "0  1.594506 -0.051608  0.663234    ...    -0.850465 -0.622990 -1.833057   \n",
       "1  2.619246 -0.765884 -0.093780    ...    -0.819750  0.012037  2.038836   \n",
       "2 -4.219054 -1.184919 -1.240310    ...    -0.604501  0.750054 -3.360521   \n",
       "3  4.499666  1.038741 -1.092716    ...     1.022959  1.275598 -3.480110   \n",
       "4 -4.290282 -1.761308  0.807652    ...     0.513906 -1.803473  0.518579   \n",
       "\n",
       "         33        34        35        36        37        38        39  \n",
       "0  0.293024  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1  0.468579 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2  0.856988 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3 -1.065252  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -0.205029 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025596</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024088</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>1.092329</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>0.497342</td>\n",
       "      <td>-0.037883</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>-0.542491</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.483507</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.567185</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>-0.892659</td>\n",
       "      <td>0.609451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008282</td>\n",
       "      <td>1.016298</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>0.970575</td>\n",
       "      <td>4.538834</td>\n",
       "      <td>0.989128</td>\n",
       "      <td>2.118819</td>\n",
       "      <td>2.232256</td>\n",
       "      <td>1.001064</td>\n",
       "      <td>1.013520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011645</td>\n",
       "      <td>1.001375</td>\n",
       "      <td>2.239939</td>\n",
       "      <td>1.022456</td>\n",
       "      <td>2.121281</td>\n",
       "      <td>1.007044</td>\n",
       "      <td>2.227876</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>2.022022</td>\n",
       "      <td>2.045439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.365711</td>\n",
       "      <td>-3.492086</td>\n",
       "      <td>-2.695602</td>\n",
       "      <td>-3.460471</td>\n",
       "      <td>-16.421901</td>\n",
       "      <td>-3.041250</td>\n",
       "      <td>-7.224761</td>\n",
       "      <td>-6.509084</td>\n",
       "      <td>-3.145588</td>\n",
       "      <td>-2.749812</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.379194</td>\n",
       "      <td>-2.971125</td>\n",
       "      <td>-7.840890</td>\n",
       "      <td>-2.999564</td>\n",
       "      <td>-7.124105</td>\n",
       "      <td>-2.952358</td>\n",
       "      <td>-5.452254</td>\n",
       "      <td>-3.473913</td>\n",
       "      <td>-8.051722</td>\n",
       "      <td>-7.799086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.669010</td>\n",
       "      <td>-0.693937</td>\n",
       "      <td>-0.698830</td>\n",
       "      <td>-0.617557</td>\n",
       "      <td>-1.801997</td>\n",
       "      <td>-0.732265</td>\n",
       "      <td>-0.838619</td>\n",
       "      <td>-1.604037</td>\n",
       "      <td>-0.677562</td>\n",
       "      <td>-0.682220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.659457</td>\n",
       "      <td>-0.696032</td>\n",
       "      <td>-2.121943</td>\n",
       "      <td>-0.664550</td>\n",
       "      <td>-1.879247</td>\n",
       "      <td>-0.642861</td>\n",
       "      <td>-1.059786</td>\n",
       "      <td>-0.691162</td>\n",
       "      <td>-2.220126</td>\n",
       "      <td>-0.565041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.027895</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.862818</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.582321</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>-0.036110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>0.049778</td>\n",
       "      <td>-0.568262</td>\n",
       "      <td>-0.028097</td>\n",
       "      <td>-0.493575</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>0.038284</td>\n",
       "      <td>-0.855470</td>\n",
       "      <td>0.779944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.762520</td>\n",
       "      <td>0.682753</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.640743</td>\n",
       "      <td>3.843172</td>\n",
       "      <td>0.671456</td>\n",
       "      <td>1.913664</td>\n",
       "      <td>1.438304</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.665364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747031</td>\n",
       "      <td>0.699917</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>1.005795</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>2.122157</td>\n",
       "      <td>0.693535</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>1.992193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.326246</td>\n",
       "      <td>3.583870</td>\n",
       "      <td>2.546507</td>\n",
       "      <td>3.088738</td>\n",
       "      <td>17.565345</td>\n",
       "      <td>3.102997</td>\n",
       "      <td>7.592666</td>\n",
       "      <td>7.130097</td>\n",
       "      <td>3.145258</td>\n",
       "      <td>3.919426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844792</td>\n",
       "      <td>3.688047</td>\n",
       "      <td>7.160379</td>\n",
       "      <td>3.353631</td>\n",
       "      <td>6.005818</td>\n",
       "      <td>3.420561</td>\n",
       "      <td>6.603499</td>\n",
       "      <td>3.492548</td>\n",
       "      <td>5.774120</td>\n",
       "      <td>6.803984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
       "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
       "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
       "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
       "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
       "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
       "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597   \n",
       "std       0.989128     2.118819     2.232256     1.001064     1.013520   \n",
       "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812   \n",
       "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220   \n",
       "50%       0.027041     0.582321     0.018809     0.022092    -0.036110   \n",
       "75%       0.671456     1.913664     1.438304     0.741310     0.665364   \n",
       "max       3.102997     7.592666     7.130097     3.145258     3.919426   \n",
       "\n",
       "          ...                30           31           32           33  \\\n",
       "count     ...       1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      ...          0.030651     0.022951    -0.542491    -0.011608   \n",
       "std       ...          1.011645     1.001375     2.239939     1.022456   \n",
       "min       ...         -3.379194    -2.971125    -7.840890    -2.999564   \n",
       "25%       ...         -0.659457    -0.696032    -2.121943    -0.664550   \n",
       "50%       ...          0.049416     0.049778    -0.568262    -0.028097   \n",
       "75%       ...          0.747031     0.699917     0.939348     0.651374   \n",
       "max       ...          2.844792     3.688047     7.160379     3.353631   \n",
       "\n",
       "                34           35           36           37           38  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     -0.483507     0.033371     0.567185     0.006849    -0.892659   \n",
       "std       2.121281     1.007044     2.227876     0.997635     2.022022   \n",
       "min      -7.124105    -2.952358    -5.452254    -3.473913    -8.051722   \n",
       "25%      -1.879247    -0.642861    -1.059786    -0.691162    -2.220126   \n",
       "50%      -0.493575     0.037732     0.455474     0.038284    -0.855470   \n",
       "75%       1.005795     0.691800     2.122157     0.693535     0.388698   \n",
       "max       6.005818     3.420561     6.603499     3.492548     5.774120   \n",
       "\n",
       "                39  \n",
       "count  1000.000000  \n",
       "mean      0.609451  \n",
       "std       2.045439  \n",
       "min      -7.799086  \n",
       "25%      -0.565041  \n",
       "50%       0.779944  \n",
       "75%       1.992193  \n",
       "max       6.803984  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, predict and solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr , X_vl , Y_tr, Y_vl = train_test_split(train, train_labels, test_size=0.2, random_state=42)\n",
    "Y_tr = np.ravel(Y_tr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_tr, Y_tr)\n",
    "acc_log = round(logreg.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_tr, Y_tr)\n",
    "acc_svc = round(svc.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors algorithm (or k-NN for short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_tr, Y_tr)\n",
    "acc_knn = round(knn.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_tr, Y_tr)\n",
    "acc_gaussian = round(gaussian.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whale/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_tr, Y_tr)\n",
    "acc_perceptron = round(perceptron.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_tr, Y_tr)\n",
    "acc_linear_svc = round(linear_svc.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whale/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_tr, Y_tr)\n",
    "acc_sgd = round(sgd.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_tr, Y_tr)\n",
    "acc_decision_tree = round(decision_tree.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_tr, Y_tr)\n",
    "acc_random_forest = round(random_forest.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whale/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightGBM = LGBMClassifier(max_depth=4, n_estimators=100, colsample_bytree=1, learning_rate=0.1)\n",
    "lightGBM.fit(X_tr, Y_tr)\n",
    "acc_lightGBM = round(lightGBM.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 7)\n",
    "x_all = pd.concat([train, test])\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        # Fit a mixture of Gaussians with EM\n",
    "        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm test= gmm\n",
    "\n",
    "best_gmm.fit(x_all)\n",
    "X_tr = best_gmm.predict_proba(X_tr)\n",
    "X_vl = best_gmm.predict_proba(X_vl)\n",
    "train = best_gmm.predict_proba(train)\n",
    "\n",
    "\n",
    "test = best_gmm.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whale/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightGBM = LGBMClassifier(max_depth=4, n_estimators=100, colsample_bytree=1, learning_rate=0.1)\n",
    "lightGBM.fit(X_tr, Y_tr)\n",
    "acc_lightGBM = round(lightGBM.score(X_vl, Y_vl) * 100, 2)\n",
    "acc_lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whale/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/whale/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/whale/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "lightGBM.fit(train, train_labels)\n",
    "res = lightGBM.predict(test)\n",
    "\n",
    "res = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.reset_index().rename(columns={'index':'Id' , 0:'Solution'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['Id'] = res['Id'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>89.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>89.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Score\n",
       "0     Support Vector Machines   89.5\n",
       "3               Random Forest   89.5\n",
       "9                    LightGBM   89.0\n",
       "1                         KNN   87.5\n",
       "2         Logistic Regression   82.5\n",
       "4                 Naive Bayes   82.0\n",
       "7                  Linear SVC   82.0\n",
       "8               Decision Tree   80.5\n",
       "6  Stochastic Gradient Decent   73.5\n",
       "5                  Perceptron   58.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree', 'LightGBM'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree, acc_lightGBM]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>1.262429</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.480585</td>\n",
       "      <td>-0.017228</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>-0.006664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018914</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>-0.476895</td>\n",
       "      <td>0.016175</td>\n",
       "      <td>-0.508713</td>\n",
       "      <td>-0.002295</td>\n",
       "      <td>0.451234</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>-1.003258</td>\n",
       "      <td>0.539873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.009514</td>\n",
       "      <td>1.011432</td>\n",
       "      <td>0.996685</td>\n",
       "      <td>0.989010</td>\n",
       "      <td>4.527492</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>2.102394</td>\n",
       "      <td>2.204673</td>\n",
       "      <td>0.989207</td>\n",
       "      <td>0.991570</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003450</td>\n",
       "      <td>1.003326</td>\n",
       "      <td>2.202519</td>\n",
       "      <td>1.015779</td>\n",
       "      <td>2.097448</td>\n",
       "      <td>1.008415</td>\n",
       "      <td>2.187677</td>\n",
       "      <td>1.000152</td>\n",
       "      <td>1.979629</td>\n",
       "      <td>2.011646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.568633</td>\n",
       "      <td>-4.238067</td>\n",
       "      <td>-3.587473</td>\n",
       "      <td>-3.646144</td>\n",
       "      <td>-17.296514</td>\n",
       "      <td>-3.500646</td>\n",
       "      <td>-9.157707</td>\n",
       "      <td>-7.867021</td>\n",
       "      <td>-4.037177</td>\n",
       "      <td>-3.666707</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.545617</td>\n",
       "      <td>-3.914329</td>\n",
       "      <td>-8.510309</td>\n",
       "      <td>-4.702577</td>\n",
       "      <td>-8.860839</td>\n",
       "      <td>-3.579675</td>\n",
       "      <td>-9.034930</td>\n",
       "      <td>-3.820679</td>\n",
       "      <td>-8.174851</td>\n",
       "      <td>-7.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.669886</td>\n",
       "      <td>-0.678792</td>\n",
       "      <td>-0.665240</td>\n",
       "      <td>-0.662560</td>\n",
       "      <td>-1.669099</td>\n",
       "      <td>-0.688766</td>\n",
       "      <td>-0.894049</td>\n",
       "      <td>-1.521762</td>\n",
       "      <td>-0.654169</td>\n",
       "      <td>-0.665439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689220</td>\n",
       "      <td>-0.664532</td>\n",
       "      <td>-1.986040</td>\n",
       "      <td>-0.673810</td>\n",
       "      <td>-1.908190</td>\n",
       "      <td>-0.689363</td>\n",
       "      <td>-1.071005</td>\n",
       "      <td>-0.667359</td>\n",
       "      <td>-2.293291</td>\n",
       "      <td>-0.717376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.010758</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>1.123982</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.534536</td>\n",
       "      <td>-0.021020</td>\n",
       "      <td>-0.006291</td>\n",
       "      <td>-0.005408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033990</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>-0.459278</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>-0.481508</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>0.419585</td>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-1.004007</td>\n",
       "      <td>0.637040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.703350</td>\n",
       "      <td>0.684755</td>\n",
       "      <td>0.658111</td>\n",
       "      <td>0.683506</td>\n",
       "      <td>4.002391</td>\n",
       "      <td>0.690966</td>\n",
       "      <td>1.890960</td>\n",
       "      <td>1.460165</td>\n",
       "      <td>0.676678</td>\n",
       "      <td>0.654349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655757</td>\n",
       "      <td>0.682167</td>\n",
       "      <td>1.026158</td>\n",
       "      <td>0.691832</td>\n",
       "      <td>0.957351</td>\n",
       "      <td>0.666330</td>\n",
       "      <td>1.938350</td>\n",
       "      <td>0.667539</td>\n",
       "      <td>0.321595</td>\n",
       "      <td>1.897324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.843549</td>\n",
       "      <td>3.538868</td>\n",
       "      <td>3.716102</td>\n",
       "      <td>3.667817</td>\n",
       "      <td>20.551947</td>\n",
       "      <td>4.565496</td>\n",
       "      <td>7.882210</td>\n",
       "      <td>7.391208</td>\n",
       "      <td>3.706671</td>\n",
       "      <td>3.322649</td>\n",
       "      <td>...</td>\n",
       "      <td>3.624639</td>\n",
       "      <td>4.251316</td>\n",
       "      <td>8.598575</td>\n",
       "      <td>4.157051</td>\n",
       "      <td>6.851583</td>\n",
       "      <td>3.911722</td>\n",
       "      <td>8.624332</td>\n",
       "      <td>3.860112</td>\n",
       "      <td>7.125848</td>\n",
       "      <td>9.464492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \n",
       "mean      0.011814     0.004261    -0.001708     0.008614     1.262429   \n",
       "std       1.009514     1.011432     0.996685     0.989010     4.527492   \n",
       "min      -3.568633    -4.238067    -3.587473    -3.646144   -17.296514   \n",
       "25%      -0.669886    -0.678792    -0.665240    -0.662560    -1.669099   \n",
       "50%       0.006104     0.010758     0.007384     0.009027     1.123982   \n",
       "75%       0.703350     0.684755     0.658111     0.683506     4.002391   \n",
       "max       3.843549     3.538868     3.716102     3.667817    20.551947   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \n",
       "mean      0.006003     0.480585    -0.017228     0.006883    -0.006664   \n",
       "std       0.999623     2.102394     2.204673     0.989207     0.991570   \n",
       "min      -3.500646    -9.157707    -7.867021    -4.037177    -3.666707   \n",
       "25%      -0.688766    -0.894049    -1.521762    -0.654169    -0.665439   \n",
       "50%       0.011476     0.534536    -0.021020    -0.006291    -0.005408   \n",
       "75%       0.690966     1.890960     1.460165     0.676678     0.654349   \n",
       "max       4.565496     7.882210     7.391208     3.706671     3.322649   \n",
       "\n",
       "          ...                30           31           32           33  \\\n",
       "count     ...       9000.000000  9000.000000  9000.000000  9000.000000   \n",
       "mean      ...         -0.018914     0.007282    -0.476895     0.016175   \n",
       "std       ...          1.003450     1.003326     2.202519     1.015779   \n",
       "min       ...         -4.545617    -3.914329    -8.510309    -4.702577   \n",
       "25%       ...         -0.689220    -0.664532    -1.986040    -0.673810   \n",
       "50%       ...         -0.033990    -0.003370    -0.459278     0.013170   \n",
       "75%       ...          0.655757     0.682167     1.026158     0.691832   \n",
       "max       ...          3.624639     4.251316     8.598575     4.157051   \n",
       "\n",
       "                34           35           36           37           38  \\\n",
       "count  9000.000000  9000.000000  9000.000000  9000.000000  9000.000000   \n",
       "mean     -0.508713    -0.002295     0.451234    -0.002042    -1.003258   \n",
       "std       2.097448     1.008415     2.187677     1.000152     1.979629   \n",
       "min      -8.860839    -3.579675    -9.034930    -3.820679    -8.174851   \n",
       "25%      -1.908190    -0.689363    -1.071005    -0.667359    -2.293291   \n",
       "50%      -0.481508    -0.000858     0.419585    -0.003255    -1.004007   \n",
       "75%       0.957351     0.666330     1.938350     0.667539     0.321595   \n",
       "max       6.851583     3.911722     8.624332     3.860112     7.125848   \n",
       "\n",
       "                39  \n",
       "count  9000.000000  \n",
       "mean      0.539873  \n",
       "std       2.011646  \n",
       "min      -7.945400  \n",
       "25%      -0.717376  \n",
       "50%       0.637040  \n",
       "75%       1.897324  \n",
       "max       9.464492  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
