{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whale/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(19)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[10], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[30], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[50], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[98], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim = num_pixels, kernel_initializer = 'normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer = 'normal', activation = 'softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset, allowing you to see the skill of the model as it trains. A verbose value of 2 is used to reduce the output to one line for each training epoch."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 200, verbose = 2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #The layer has 30 feature maps, which with the size of 5×5 and a rectifier activation function. \n",
    "    #This is the input layer, expecting images with the structure outline above [pixels][width][height]\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    \n",
    "    #pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    #convolutional layer with 15 feature maps of size 3×3\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    \n",
    "    #Pooling layer taking the max over 2*2 patches\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    #regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons  \n",
    "    #in the layer in order to reduce overfitting\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed \n",
    "    #by standard fully connected layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #fully connected layer with 128 neurons and rectifier activation function.\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    #Fully connected layer with 50 neurons and rectifier activation\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    \n",
    "    #output layer has 10 neurons for the 10 classes and a softmax activation function to output  \n",
    "    #probability-like predictions for each class\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.3733 - acc: 0.8827 - val_loss: 0.0750 - val_acc: 0.9778\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0902 - acc: 0.9723 - val_loss: 0.0556 - val_acc: 0.9821\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 70s 1ms/step - loss: 0.0678 - acc: 0.9791 - val_loss: 0.0374 - val_acc: 0.9879\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0539 - acc: 0.9831 - val_loss: 0.0337 - val_acc: 0.9895\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0470 - acc: 0.9853 - val_loss: 0.0310 - val_acc: 0.9897\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0404 - acc: 0.9874 - val_loss: 0.0328 - val_acc: 0.9902\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.0376 - acc: 0.9884 - val_loss: 0.0317 - val_acc: 0.9900\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.0330 - acc: 0.9894 - val_loss: 0.0272 - val_acc: 0.9906\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.0293 - acc: 0.9911 - val_loss: 0.0271 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0287 - acc: 0.9908 - val_loss: 0.0275 - val_acc: 0.9907\n",
      "Large CNN Error: 0.93%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
